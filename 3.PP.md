# 项目计划 (PP)

## 1. 项目目标

本项目旨在完成 **动态记忆森林 (Dynamic Memory Forest)** 的 v3.0 开发。核心目标是构建一个强大的、结构化的长期记忆系统，并将其定位为一个**可通过标准MCP协议集成的AI工具**。依赖的数据库服务 (PostgreSQL, Qdrant) 将被编排为一个名为 persistent-memory-agent-system 的统一Docker项目，主应用在本地直接与之交互，以确保开发效率和部署一致性。

## 2. 核心里程碑

-   **M1: 基础架构与数据模型搭建完成**
    -   **通过 `docker-compose up` 成功启动所有服务 (PostgreSQL, Qdrant)。**
    -   主应用能够成功连接到所有依赖服务。
    -   核心AI服务的抽象接口定义完毕。
-   **M2: "智能归档"流程实现**
    -   `build_memory_tree` 功能开发完成，能够将一份文档成功转化为数据库中的一棵或多棵摘要树。
    -   所有节点数据正确同步写入 PostgreSQL 和 Qdrant。
-   **M3: "代理式回忆"核心逻辑实现**
    -   `retrieve_from_memory` 和 `_archive_drill_down` 功能开发完成。
    -   能够实现 "向量检索 -> LCA合并 -> 按需钻取" 的核心回忆逻辑。
-   **M4: MCP工具API与端到端集成**
    -   `explore_memory_node` 工具通过MCP协议成功暴露。
    -   在完整的Docker Compose环境中，通过端到端测试验证完整用户故事。

## 3. 开发阶段与任务分解

### **阶段一: 地基搭建 (对应 M1)**

**目标**: 建立项目骨架，准备好所有数据库和本地AI服务依赖。

- [x] **任务 1.1: 环境与依赖**
  - [x] `requirements.txt`: 确认并安装所有依赖到**本地Python环境**。
  - [x] **创建 `.env.example` 文件** 来管理环境变量，并创建实际的 `.env` 文件（添加到 `.gitignore`）。**URL需配置为`localhost`地址**。

- [x] **任务 1.2: 依赖容器化编排**
  - [x] **创建 `docker-compose.yml`** 文件，定义名为 `persistent-memory-agent-system` 的项目，并编排**两个依赖服务**: `postgres-db`, `qdrant-db`。**主应用不包含在此文件中**。

- [x] **任务 1.3: 定义开发工作流**
  - [x] 明确两步启动流程：
      1.  在终端中运行 `docker-compose up -d` 启动所有背景服务。
      2.  在另一个终端中，从项目根目录运行 `uvicorn src.server:app --reload` 启动主应用，以利用热重载进行开发。
  - [x] **验证连接**: 启动所有服务后，确认主应用能够通过 `localhost` 访问到所有服务的端口。

- [x] **任务 1.4: 数据库初始化脚本**
  - [x] `initialize_db.py`: 编写脚本，从环境变量中读取数据库连接信息，连接到运行在Docker中的PostgreSQL服务，并创建`archives`和`memory_nodes`表。

- [x] **任务 1.5: 核心服务抽象与模拟**
    - [x] `model_services.py`: 创建`LLMService`, `EmbeddingService`, `RerankerService`的基类或协议。
    - [x] `tests/mocks.py`: 实现上述服务的模拟版本，用于快速单元测试。

- [x] **任务 1.6: `MemoryService` 结构搭建**
    - [x] `memory_service.py`: 创建 `MemoryService` 类，初始化数据库连接（PostgreSQL/Qdrant）。

### **阶段二: 记忆树构建 (对应 M2)**

**目标**: 实现完整的 "智能归档" 流程，将文本转化为结构化的树。

-   [ ] **任务 2.1: 叶子节点创建**
    -   [ ] 实现 `_create_leaf_nodes`:
        -   集成 `RecursiveCharacterTextSplitter`。
        -   调用（Mock）LLM和Embedding服务。
        -   实现向PostgreSQL `INSERT` 节点元数据并获取`node_id`的逻辑。
        -   实现向Qdrant `upsert` 向量及payload的逻辑。
        -   实现二次`UPDATE`以设置`path`字段。
-   [ ] **任务 2.2: 迭代合并逻辑**
    -   [ ] 实现 `_get_current_root_node_ids`: 简单的SQL查询。
    -   [ ] 实现 `_find_best_merge_pair`:
        -   从Qdrant检索向量。
        -   从PostgreSQL检索`content`以检查长度限制。
        -   实现余弦相似度计算和比较逻辑。
    -   [ ] 实现 `_update_subtree_paths_and_depth`: **(关键/复杂任务)** 使用队列（BFS）实现高效的子树路径和深度更新。
    -   [ ] 实现 `_merge_nodes`:
        -   整合内容，调用AI服务生成新摘要和向量。
        -   插入新的父节点到PostgreSQL和Qdrant。
        -   更新子节点的`parent_id`。
        -   调用 `_update_subtree_paths_and_depth`。
-   [ ] **任务 2.3: 流程编排**
    -   [ ] 实现 `build_memory_tree`: 将上述所有函数按TDD中的循环逻辑串联起来。

### **阶段三: 记忆检索与探索 (对应 M3)**

**目标**: 实现两阶段回忆逻辑，为MCP工具提供核心能力。

-   [ ] **任务 3.1: 初步检索与LCA合并**
    -   [ ] 实现 `_initial_vector_retrieval`: 执行Qdrant向量搜索并从PostgreSQL获取节点详情。
    -   [ ] `utils.py`: 实现 `find_longest_common_prefix` 辅助函数。
    -   [ ] 实现 `_find_lowest_common_ancestor`: **(新核心逻辑)** 根据`path`前缀查找LCA节点。
    -   [ ] 实现 `retrieve_from_memory`: 编排 "检索 -> 分组 -> LCA合并" 流程。
-   [ ] **任务 3.2: 向下钻取逻辑**
    -   [ ] 实现 `_archive_drill_down`:
        -   查询指定`parent_id`的所有子节点。
        -   调用（Mock）Reranker服务进行排序和筛选。
        -   根据阈值过滤结果。

### **阶段四: API集成与测试 (对应 M4)**

- [ ] **任务 4.1 & 4.2**: (FastAPI 端点和 MCP 集成，无变化)
- [ ] **任务 4.3: 连接真实服务与端到端测试**
    - [ ] `llm_providers.py`: 实现连接到本地Docker化模型服务的客户端，**URL从环境变量中读取（如 `EMBEDDING_SERVICE_URL`）**。
    - [ ] 更新 `MemoryForestManager` 以使用指向本地服务的真实客户端和PostgreSQL数据库连接。
    - [ ] **启动完整环境**: 使用 `docker-compose up --build` 启动所有服务。
    - [ ] 编写并执行端到端测试脚本，验证完整流程。

## 4. 技术栈

-   **后端框架**: FastAPI
-   **数据库**: **PostgreSQL** (元数据), Qdrant (向量存储)
-   **核心逻辑**: Python
-   **AI模型交互**:
    -   **本地**: 通过HTTP请求与本地Docker容器中的模型服务交互。
    -   **外部 (可选)**: 通过API与外部LLM服务交互。
-   **文本处理**: `langchain.text_splitter`
-   **API协议**: HTTP/JSON, MCP (`fastapi-mcp`)
-   **部署**: **使用 Docker Compose 管理依赖服务 (数据库)，主应用在主机本地运行以便于调试**

## 5. 测试策略

-   **单元测试**: 针对独立函数，如 `find_longest_common_prefix`, `_update_subtree_paths_and_depth` 的算法正确性进行测试。
-   **集成测试**: 测试与数据库（PostgreSQL, Qdrant）和模拟AI服务的交互是否正确。
-   **端到端测试**: (见任务4.3) 在**完整的Docker Compose环境**下，模拟完整的用户故事，验证整个系统的功能正确性。